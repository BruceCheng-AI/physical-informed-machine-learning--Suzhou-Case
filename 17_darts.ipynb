{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>precip_fengqiao</th>\n",
       "      <th>precip_suzhou</th>\n",
       "      <th>T2M</th>\n",
       "      <th>T2M_MAX</th>\n",
       "      <th>T2M_MIN</th>\n",
       "      <th>ETo_HS</th>\n",
       "      <th>runoff_fengqiao</th>\n",
       "      <th>runoff_suzhou</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1989-01-01</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.81</td>\n",
       "      <td>10.07</td>\n",
       "      <td>1.12</td>\n",
       "      <td>1.22</td>\n",
       "      <td>0.018179</td>\n",
       "      <td>0.018179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-01-02</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.83</td>\n",
       "      <td>12.39</td>\n",
       "      <td>0.13</td>\n",
       "      <td>1.49</td>\n",
       "      <td>0.036330</td>\n",
       "      <td>0.036330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-01-03</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.70</td>\n",
       "      <td>12.26</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.054453</td>\n",
       "      <td>0.054453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-01-04</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.05</td>\n",
       "      <td>12.15</td>\n",
       "      <td>4.04</td>\n",
       "      <td>1.29</td>\n",
       "      <td>0.072550</td>\n",
       "      <td>0.072550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989-01-05</th>\n",
       "      <td>0.9</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.32</td>\n",
       "      <td>12.61</td>\n",
       "      <td>3.19</td>\n",
       "      <td>1.41</td>\n",
       "      <td>0.090644</td>\n",
       "      <td>0.090633</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-27</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.28</td>\n",
       "      <td>8.31</td>\n",
       "      <td>-2.52</td>\n",
       "      <td>1.18</td>\n",
       "      <td>72.722993</td>\n",
       "      <td>67.458859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-28</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.28</td>\n",
       "      <td>7.74</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.03</td>\n",
       "      <td>72.725316</td>\n",
       "      <td>67.461033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-29</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.78</td>\n",
       "      <td>6.32</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>72.727635</td>\n",
       "      <td>67.463204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-30</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.04</td>\n",
       "      <td>8.09</td>\n",
       "      <td>-1.19</td>\n",
       "      <td>1.14</td>\n",
       "      <td>72.729951</td>\n",
       "      <td>67.465372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-12-31</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.19</td>\n",
       "      <td>9.94</td>\n",
       "      <td>-0.44</td>\n",
       "      <td>1.27</td>\n",
       "      <td>72.732264</td>\n",
       "      <td>67.467536</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12418 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            precip_fengqiao  precip_suzhou   T2M  T2M_MAX  T2M_MIN  ETo_HS  \\\n",
       "time                                                                         \n",
       "1989-01-01              0.0            0.0  4.81    10.07     1.12    1.22   \n",
       "1989-01-02              0.0            0.0  5.83    12.39     0.13    1.49   \n",
       "1989-01-03              0.0            0.0  6.70    12.26     3.40    1.32   \n",
       "1989-01-04              0.0            0.0  7.05    12.15     4.04    1.29   \n",
       "1989-01-05              0.9            0.5  7.32    12.61     3.19    1.41   \n",
       "...                     ...            ...   ...      ...      ...     ...   \n",
       "2022-12-27              0.0            0.0  2.28     8.31    -2.52    1.18   \n",
       "2022-12-28              0.0            0.0  3.28     7.74     0.19    1.03   \n",
       "2022-12-29              0.0            0.0  2.78     6.32     0.17    0.91   \n",
       "2022-12-30              0.0            0.0  3.04     8.09    -1.19    1.14   \n",
       "2022-12-31              0.0            0.0  4.19     9.94    -0.44    1.27   \n",
       "\n",
       "            runoff_fengqiao  runoff_suzhou  \n",
       "time                                        \n",
       "1989-01-01         0.018179       0.018179  \n",
       "1989-01-02         0.036330       0.036330  \n",
       "1989-01-03         0.054453       0.054453  \n",
       "1989-01-04         0.072550       0.072550  \n",
       "1989-01-05         0.090644       0.090633  \n",
       "...                     ...            ...  \n",
       "2022-12-27        72.722993      67.458859  \n",
       "2022-12-28        72.725316      67.461033  \n",
       "2022-12-29        72.727635      67.463204  \n",
       "2022-12-30        72.729951      67.465372  \n",
       "2022-12-31        72.732264      67.467536  \n",
       "\n",
       "[12418 rows x 8 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load data\n",
    "history = pd.read_csv('../data/results/history.csv', index_col=0)\n",
    "ssp245 = pd.read_csv('../data/results/ssp245.csv', index_col=0)\n",
    "ssp585 = pd.read_csv('../data/results/ssp585.csv', index_col=0)\n",
    "history_wl = pd.read_csv('../data/results/history_wl.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from darts import TimeSeries\n",
    "from darts.models import RNNModel\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import mape, r2_score\n",
    "from darts.metrics import rmse\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 从数据框创建时间序列\n",
    "series_history = TimeSeries.from_dataframe(history.reset_index(), 'time')\n",
    "series_wl = TimeSeries.from_dataframe(history_wl.reset_index(), 'time', ['water_level'])\n",
    "\n",
    "# 数据预处理\n",
    "scaler_history = Scaler()\n",
    "scaler_wl = Scaler()\n",
    "\n",
    "series_history_scaled = scaler_history.fit_transform(series_history)\n",
    "series_wl_scaled = scaler_wl.fit_transform(series_wl)\n",
    "\n",
    "wl_train, _ = series_wl_scaled.split_before(0.8)\n",
    "\n",
    "def evaluate_model(model,past_covariates=None, future_covariates=None):\n",
    "    # We backtest the model on the last 20% of the flow series, with a horizon of 10 steps:\n",
    "    backtest = model.historical_forecasts(series=series_wl_scaled, \n",
    "                                          past_covariates=past_covariates,\n",
    "                                          future_covariates=future_covariates,\n",
    "                                          start=0.8, \n",
    "                                          retrain=False,\n",
    "                                          verbose=True, \n",
    "                                          forecast_horizon=10)\n",
    "    \n",
    "    # Iterate over the list of TimeSeries objects and call the plot method on each one\n",
    "    for ts in [series_wl_scaled[-len(backtest)-100:], backtest]:\n",
    "        ts.plot(label='backtest (n=10)')\n",
    "    \n",
    "    print('Backtest RMSE = {}'.format(rmse(series_wl_scaled, backtest)))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from darts import TimeSeries\n",
    "from darts.dataprocessing.transformers import Scaler\n",
    "from darts.metrics import rmse\n",
    "import torch\n",
    "from darts.models import BlockRNNModel\n",
    "\n",
    "\n",
    "# load data\n",
    "history = pd.read_csv('../data/results/history.csv', index_col=0)\n",
    "ssp245 = pd.read_csv('../data/results/ssp245.csv', index_col=0)\n",
    "ssp585 = pd.read_csv('../data/results/ssp585.csv', index_col=0)\n",
    "history_wl = pd.read_csv('../data/results/history_wl.csv', index_col=0)\n",
    "\n",
    "# 从数据框创建时间序列\n",
    "series_history = TimeSeries.from_dataframe(history.reset_index(), 'time')\n",
    "series_wl = TimeSeries.from_dataframe(history_wl.reset_index(), 'time', ['water_level'])\n",
    "\n",
    "\n",
    "\n",
    "# 数据预处理\n",
    "scaler_history = Scaler()\n",
    "scaler_wl = Scaler()\n",
    "\n",
    "series_history_scaled = scaler_history.fit_transform(series_history)\n",
    "series_wl_scaled = scaler_wl.fit_transform(series_wl)\n",
    "\n",
    "# Determine the split point\n",
    "split_idx = int(len(series_wl_scaled) * 0.8)\n",
    "split_date = series_wl_scaled.time_index[split_idx]\n",
    "\n",
    "# split data into training and validation sets\n",
    "wl_train = series_wl_scaled.split_before(split_date)\n",
    "wl_val = series_wl_scaled.split_after(split_date)\n",
    "\n",
    "covariates_history_train = series_history_scaled.split_before(split_date)\n",
    "covariates_history_val = series_history_scaled.split_after(split_date)\n",
    "\n",
    "\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "model = BlockRNNModel(\n",
    "    model='LSTM', \n",
    "    input_chunk_length=30, \n",
    "    output_chunk_length=10,\n",
    "    n_rnn_layers=2,\n",
    "    random_state=42,\n",
    "    pl_trainer_kwargs = {\"accelerator\": \"gpu\", \"devices\": [0]}  \n",
    ")\n",
    "\n",
    "model.fit(\n",
    "    series=wl_train,\n",
    "    past_covariates=covariates_history_train,\n",
    "    verbose=True,\n",
    "    epochs=5\n",
    ")\n",
    "\n",
    "\n",
    "# 使用模型进行预测\n",
    "prediction = model.predict(n=len(wl_val), series=wl_val, past_covariates=covariates_history_val)\n",
    "\n",
    "\n",
    "\n",
    "# 计算 RMSE\n",
    "error = rmse(prediction, wl_val)\n",
    "\n",
    "print(f'RMSE: {error}')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "features_train, features_val, target_train, target_val = train_test_split(\n",
    "    history,\n",
    "    history_wl,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "# 添加常数列作为截距项\n",
    "features = sm.add_constant(features_train)\n",
    "# 拟合VAR模型\n",
    "model = sm.OLS(target_train, features)\n",
    "results = model.fit()\n",
    "\n",
    "features_val = sm.add_constant(features_val)\n",
    "\n",
    "predictions = results.predict(features_val)\n",
    "\n",
    "rmse =  np.sqrt(mean_squared_error(target_val, predictions))\n",
    "\n",
    "# R2 score\n",
    "r2 = r2_score(target_val, predictions)\n",
    "\n",
    "print(f'RMSE: {rmse}')\n",
    "print(f'R2: {r2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wl_ssp245.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suzhou = pd.read_csv('../data/intermediate/suzhou_interpolated.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "suzhou['water_level'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_wl.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prophet import Prophet\n",
    "df = pd.DataFrame({'ds': history_wl.index, 'y': history_wl['water_level']})\n",
    "df['runoff_fengqiao'] = history['runoff_fengqiao']\n",
    "df['runoff_suzhou'] = history['runoff_suzhou']\n",
    "df['precip_fengqiao'] = history['precip_fengqiao']\n",
    "df['precip_suzhou'] = history['precip_suzhou']\n",
    "df['T2M'] = history['T2M']\n",
    "df['T2M_MAX'] = history['T2M_MAX']\n",
    "df['T2M_MIN'] = history['T2M_MIN']\n",
    "df['ETo_HS'] = history['ETo_HS']\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 设置随机种子，以确保结果可重现\n",
    "random_seed = 42\n",
    "\n",
    "# 使用80%的数据作为训练集，20%的数据作为测试集\n",
    "train_size = 0.8\n",
    "\n",
    "# 注意，你需要先将'ds'列转换为日期类型\n",
    "df['ds'] = pd.to_datetime(df['ds'])\n",
    "\n",
    "# 按时间顺序排序，确保拆分是按照时间序列的顺序进行的\n",
    "df = df.sort_values('ds')\n",
    "\n",
    "# 计算训练集的大小\n",
    "train_len = int(train_size * len(df))\n",
    "\n",
    "# 划分数据集\n",
    "df_train = df.iloc[:train_len]\n",
    "df_test = df.iloc[train_len:]\n",
    "\n",
    "# 初始化Prophet模型\n",
    "m = Prophet()\n",
    "m.add_regressor('runoff_fengqiao')\n",
    "m.add_regressor('runoff_suzhou')\n",
    "m.add_regressor('precip_fengqiao')\n",
    "m.add_regressor('precip_suzhou')\n",
    "m.add_regressor('T2M')\n",
    "m.add_regressor('T2M_MAX')\n",
    "m.add_regressor('T2M_MIN')\n",
    "m.add_regressor('ETo_HS')\n",
    "\n",
    "\n",
    "m.fit(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 创建一个未来的时间段，长度为测试集的长度\n",
    "future = m.make_future_dataframe(periods=len(df_test))\n",
    "future['runoff_fengqiao'] = df['runoff_suzhou'].values\n",
    "future['runoff_suzhou'] = df['runoff_suzhou'].values\n",
    "future['precip_fengqiao'] = df['precip_fengqiao'].values\n",
    "future['precip_suzhou'] = df['precip_suzhou'].values\n",
    "future['T2M'] = df['T2M'].values\n",
    "future['T2M_MAX'] = df['T2M_MAX'].values\n",
    "future['T2M_MIN'] = df['T2M_MIN'].values\n",
    "future['ETo_HS'] = df['ETo_HS'].values\n",
    "forecast = m.predict(future)\n",
    "\n",
    "forecast_test = forecast.loc[forecast['ds'].isin(df_test['ds'])]\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "from prophet.plot import plot_cross_validation_metric\n",
    "rmse = mean_squared_error(df_test['y'], forecast_test['yhat'], squared=False)\n",
    "print('RMSE: ', rmse)\n",
    "\n",
    "r2 = r2_score(df_test['y'], forecast_test['yhat'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = r2_score(df_test['y'], forecast_test['yhat'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 你也可以使用Prophet的内置交叉验证\n",
    "df_cv = cross_validation(m, initial='730 days', period='180 days', horizon = '365 days')\n",
    "df_p = performance_metrics(df_cv)\n",
    "print(df_p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ssp585"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "future_ssp585 = pd.DataFrame({'ds': ssp585.index,'runoff_fengqiao':ssp585['runoff_fengqiao'],'runoff_suzhou':ssp585['runoff_suzhou'],'precip_fengqiao':ssp585['precip_fengqiao'],'precip_suzhou':ssp585['precip_suzhou'],'T2M':ssp585['T2M'],'T2M_MAX':ssp585['T2M_MAX'],'T2M_MIN':ssp585['T2M_MIN'],'ETo_HS':ssp585['ETo_HS']})\n",
    "\n",
    "\n",
    "forecast_ssp585 = m.predict(future_ssp585)\n",
    "\n",
    "forecast_ssp585['yhat'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "import pandas as pd\n",
    "from prophet import Prophet\n",
    "from prophet.diagnostics import cross_validation, performance_metrics\n",
    "\n",
    "param_grid = {  \n",
    "    'changepoint_prior_scale': [0.001, 0.01, 0.1, 0.5],\n",
    "    'seasonality_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "    'seasonality_mode': ['additive', 'multiplicative'],\n",
    "    'holidays_prior_scale': [0.01, 0.1, 1.0, 10.0],\n",
    "}\n",
    "\n",
    "\n",
    "# Generate all combinations of parameters\n",
    "all_params = [dict(zip(param_grid.keys(), v)) for v in itertools.product(*param_grid.values())]\n",
    "rmses = []  # Store the RMSEs for each params here\n",
    "\n",
    "# Use cross validation to evaluate all parameters\n",
    "for params in all_params:\n",
    "    m = Prophet(**params).fit(df_train)  # Fit model with given params\n",
    "    df_cv = cross_validation(m, initial='730 days', period='180 days', horizon='365 days')\n",
    "    df_p = performance_metrics(df_cv, rolling_window=1)\n",
    "    rmses.append(df_p['rmse'].values[0])\n",
    "\n",
    "# Find the best parameters\n",
    "tuning_results = pd.DataFrame(all_params)\n",
    "tuning_results['rmse'] = rmses\n",
    "print(tuning_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = tuning_results.loc[tuning_results['rmse'].idxmin()]\n",
    "\n",
    "best_params = tuning_results.loc[tuning_results['rmse'].idxmin()]\n",
    "best_rmse = best_params['rmse']\n",
    "print(\"Best Parameters:\")\n",
    "print(best_params)\n",
    "print(\"Best RMSE:\", best_rmse)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = tuning_results.loc[tuning_results['rmse'].idxmin()]\n",
    "\n",
    "prophet_params = {\n",
    "    'changepoint_prior_scale': best_params['changepoint_prior_scale'],\n",
    "    'seasonality_prior_scale': best_params['seasonality_prior_scale'],\n",
    "    'seasonality_mode': best_params['seasonality_mode'],\n",
    "    'holidays_prior_scale': best_params['holidays_prior_scale']\n",
    "}\n",
    "\n",
    "m = Prophet(**prophet_params).fit(df_train)  # 使用最佳参数拟合模型\n",
    "\n",
    "future_ssp585 = pd.DataFrame({'ds': ssp585.index, 'runoff_fengqiao': ssp585['runoff_fengqiao'], 'runoff_suzhou': ssp585['runoff_suzhou'], 'precip_fengqiao': ssp585['precip_fengqiao'], 'precip_suzhou': ssp585['precip_suzhou'], 'T2M': ssp585['T2M'], 'T2M_MAX': ssp585['T2M_MAX'], 'T2M_MIN': ssp585['T2M_MIN'], 'ETo_HS': ssp585['ETo_HS']})\n",
    "\n",
    "forecast_ssp585 = m.predict(future_ssp585)\n",
    "\n",
    "forecast_ssp585['yhat'].plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_wl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# 提取特征和目标值\n",
    "X = series_history.values().reshape(-1, 1)\n",
    "y = series_wl.values().reshape(-1, 1)\n",
    "\n",
    "# 数据归一化\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "X = scaler_X.fit_transform(X)\n",
    "y = scaler_y.fit_transform(y)\n",
    "\n",
    "# 训练SVR模型\n",
    "svr = SVR(kernel='rbf', C=1e3, gamma=0.1)\n",
    "svr.fit(X, y.ravel())\n",
    "\n",
    "# 用模型进行预测\n",
    "y_pred = svr.predict(X)\n",
    "\n",
    "# 将预测结果从归一化状态恢复到原始状态\n",
    "y_pred = scaler_y.inverse_transform(y_pred.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
